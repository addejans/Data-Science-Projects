{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook explores different examples of decision tree classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dt_without_recursion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n",
      "Training time: 0:00:20.629000\n",
      "Train accuracy: 1.0\n",
      "Time to compute train accuracy: 0:00:00.016000\n",
      "Test accuracy: 0.991152450091\n",
      "Time to compute test accuracy: 0:00:00.016000\n",
      "SK: Training time: 0:00:00.383000\n",
      "Train accuracy: 1.0\n",
      "SK: Time to compute train accuracy: 0:00:00.015000\n",
      "Test accuracy: 0.994101633394\n",
      "SK: Time to compute test accuracy: 0:00:00.016000\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree for continuous-vector input, binary output\n",
    "from __future__ import print_function, division\n",
    "from future.utils import iteritems\n",
    "from builtins import range, input\n",
    "\n",
    "import numpy as np\n",
    "from util import get_data, get_xor, get_donut\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def entropy(y):\n",
    "    # assume y is binary - 0 or 1\n",
    "    N = len(y)\n",
    "    s1 = (y == 1).sum()\n",
    "    if 0 == s1 or N == s1:\n",
    "        return 0\n",
    "    p1 = float(s1) / N\n",
    "    p0 = 1 - p1\n",
    "    # return -p0*np.log2(p0) - p1*np.log2(p1)\n",
    "    return 1 - p0*p0 - p1*p1\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, depth=0, max_depth=None):\n",
    "        # print 'depth:', depth\n",
    "        # self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.root = {} # is a tree node\n",
    "        # each node will have the attributes (k-v pairs):\n",
    "        # - col\n",
    "        # - split\n",
    "        # - left\n",
    "        # - right\n",
    "        # - prediction\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "\n",
    "        current_node = self.root\n",
    "        depth = 0\n",
    "        queue = []\n",
    "        # origX = X\n",
    "        # origY = Y\n",
    "        while True:\n",
    "\n",
    "            if len(Y) == 1 or len(set(Y)) == 1:\n",
    "                # base case, only 1 sample\n",
    "                # another base case\n",
    "                # this node only receives examples from 1 class\n",
    "                # we can't make a split\n",
    "                # self.col = None\n",
    "                # self.split = None\n",
    "                # self.left = None\n",
    "                # self.right = None\n",
    "                # self.prediction = Y[0]\n",
    "                current_node['col'] = None\n",
    "                current_node['split'] = None\n",
    "                current_node['left'] = None\n",
    "                current_node['right'] = None\n",
    "                current_node['prediction'] = Y[0]\n",
    "\n",
    "            else:\n",
    "                D = X.shape[1]\n",
    "                cols = range(D)\n",
    "\n",
    "                max_ig = 0\n",
    "                best_col = None\n",
    "                best_split = None\n",
    "                for col in cols:\n",
    "                    ig, split = self.find_split(X, Y, col)\n",
    "                    # print \"ig:\", ig\n",
    "                    if ig > max_ig:\n",
    "                        max_ig = ig\n",
    "                        best_col = col\n",
    "                        best_split = split\n",
    "\n",
    "                if max_ig == 0:\n",
    "                    # nothing we can do\n",
    "                    # no further splits\n",
    "                    # self.col = None\n",
    "                    # self.split = None\n",
    "                    # self.left = None\n",
    "                    # self.right = None\n",
    "                    # self.prediction = np.round(Y.mean())\n",
    "                    current_node['col'] = None\n",
    "                    current_node['split'] = None\n",
    "                    current_node['left'] = None\n",
    "                    current_node['right'] = None\n",
    "                    current_node['prediction'] = np.round(Y.mean())\n",
    "                else:\n",
    "                    # self.col = best_col\n",
    "                    # self.split = best_split\n",
    "                    current_node['col'] = best_col\n",
    "                    current_node['split'] = best_split\n",
    "\n",
    "                    # if self.depth == self.max_depth:\n",
    "                    if depth == self.max_depth:\n",
    "                        # self.left = None\n",
    "                        # self.right = None\n",
    "                        # self.prediction = [\n",
    "                        #     np.round(Y[X[:,best_col] < self.split].mean()),\n",
    "                        #     np.round(Y[X[:,best_col] >= self.split].mean()),\n",
    "                        # ]\n",
    "                        current_node['left'] = None\n",
    "                        current_node['right'] = None\n",
    "                        current_node['prediction'] = [\n",
    "                            np.round(Y[X[:,best_col] < self.split].mean()),\n",
    "                            np.round(Y[X[:,best_col] >= self.split].mean()),\n",
    "                        ]\n",
    "                    else:\n",
    "                        # print \"best split:\", best_split\n",
    "                        left_idx = (X[:,best_col] < best_split)\n",
    "                        # print \"left_idx.shape:\", left_idx.shape, \"len(X):\", len(X)\n",
    "                        # TODO: bad but I can't figure out a better way atm\n",
    "                        Xleft = X[left_idx]\n",
    "                        Yleft = Y[left_idx]\n",
    "                        # self.left = TreeNode(self.depth + 1, self.max_depth)\n",
    "                        # self.left.fit(Xleft, Yleft)\n",
    "                        new_node = {}\n",
    "                        current_node['left'] = new_node\n",
    "                        left_data = {\n",
    "                            'node': new_node,\n",
    "                            'X': Xleft,\n",
    "                            'Y': Yleft,\n",
    "                        }\n",
    "                        queue.insert(0, left_data)\n",
    "\n",
    "                        right_idx = (X[:,best_col] >= best_split)\n",
    "                        Xright = X[right_idx]\n",
    "                        Yright = Y[right_idx]\n",
    "                        # self.right = TreeNode(self.depth + 1, self.max_depth)\n",
    "                        # self.right.fit(Xright, Yright)\n",
    "                        new_node = {}\n",
    "                        current_node['right'] = new_node\n",
    "                        right_data = {\n",
    "                            'node': new_node,\n",
    "                            'X': Xright,\n",
    "                            'Y': Yright,\n",
    "                        }\n",
    "                        queue.insert(0, right_data)\n",
    "\n",
    "            # setup for the next iteration of the loop\n",
    "            # idea is, queue stores list of work to be done\n",
    "            if len(queue) == 0:\n",
    "                break\n",
    "\n",
    "            next_data = queue.pop()\n",
    "            current_node = next_data['node']\n",
    "            X = next_data['X']\n",
    "            Y = next_data['Y']\n",
    "\n",
    "    def find_split(self, X, Y, col):\n",
    "        # print \"finding split for col:\", col\n",
    "        x_values = X[:, col]\n",
    "        sort_idx = np.argsort(x_values)\n",
    "        x_values = x_values[sort_idx]\n",
    "        y_values = Y[sort_idx]\n",
    "\n",
    "        # Note: optimal split is the midpoint between 2 points\n",
    "        # Note: optimal split is only on the boundaries between 2 classes\n",
    "\n",
    "        # if boundaries[i] is true\n",
    "        # then y_values[i] != y_values[i+1]\n",
    "        # nonzero() gives us indices where arg is true\n",
    "        # but for some reason it returns a tuple of size 1\n",
    "        boundaries = np.nonzero(y_values[:-1] != y_values[1:])[0]\n",
    "        best_split = None\n",
    "        max_ig = 0\n",
    "        last_ig = 0\n",
    "        for b in boundaries:\n",
    "            split = (x_values[b] + x_values[b+1]) / 2\n",
    "            ig = self.information_gain(x_values, y_values, split)\n",
    "            if ig < last_ig:\n",
    "                break\n",
    "            last_ig = ig\n",
    "            if ig > max_ig:\n",
    "                max_ig = ig\n",
    "                best_split = split\n",
    "        return max_ig, best_split\n",
    "\n",
    "    def information_gain(self, x, y, split):\n",
    "        # assume classes are 0 and 1\n",
    "        # print \"split:\", split\n",
    "        y0 = y[x < split]\n",
    "        y1 = y[x >= split]\n",
    "        N = len(y)\n",
    "        y0len = len(y0)\n",
    "        if y0len == 0 or y0len == N:\n",
    "            return 0\n",
    "        p0 = float(len(y0)) / N\n",
    "        p1 = 1 - p0 #float(len(y1)) / N\n",
    "        # print \"entropy(y):\", entropy(y)\n",
    "        # print \"p0:\", p0\n",
    "        # print \"entropy(y0):\", entropy(y0)\n",
    "        # print \"p1:\", p1\n",
    "        # print \"entropy(y1):\", entropy(y1)\n",
    "        return entropy(y) - p0*entropy(y0) - p1*entropy(y1)\n",
    "\n",
    "    def predict_one(self, x):\n",
    "        # use \"is not None\" because 0 means False\n",
    "        # if self.col is not None and self.split is not None:\n",
    "        #     feature = x[self.col]\n",
    "        #     if feature < self.split:\n",
    "        #         if self.left:\n",
    "        #             p = self.left.predict_one(x)\n",
    "        #         else:\n",
    "        #             p = self.prediction[0]\n",
    "        #     else:\n",
    "        #         if self.right:\n",
    "        #             p = self.right.predict_one(x)\n",
    "        #         else:\n",
    "        #             p = self.prediction[1]\n",
    "        # else:\n",
    "        #     # corresponds to having only 1 prediction\n",
    "        #     p = self.prediction\n",
    "        p = None\n",
    "        current_node = self.root\n",
    "        while True:\n",
    "            if current_node['col'] is not None and current_node['split'] is not None:\n",
    "                feature = x[current_node['col']]\n",
    "                if feature < current_node['split']:\n",
    "                    if current_node['left']:\n",
    "                        current_node = current_node['left']\n",
    "                    else:\n",
    "                        p = current_node['prediction'][0]\n",
    "                        break\n",
    "                else:\n",
    "                    if current_node['right']:\n",
    "                        current_node = current_node['right']\n",
    "                    else:\n",
    "                        p = current_node['prediction'][1]\n",
    "                        break\n",
    "            else:\n",
    "                # corresponds to having only 1 prediction\n",
    "                p = current_node['prediction']\n",
    "                break\n",
    "        return p\n",
    "\n",
    "    def predict(self, X):\n",
    "        N = len(X)\n",
    "        P = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            P[i] = self.predict_one(X[i])\n",
    "        return P\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        P = self.predict(X)\n",
    "        return np.mean(P == Y)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X, Y = get_data()\n",
    "\n",
    "    # try donut and xor\n",
    "    # from sklearn.utils import shuffle\n",
    "    # X, Y = get_xor()\n",
    "    # # X, Y = get_donut()\n",
    "    # X, Y = shuffle(X, Y)\n",
    "\n",
    "    # only take 0s and 1s since we're doing binary classification\n",
    "    idx = np.logical_or(Y == 0, Y == 1)\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "\n",
    "    # split the data\n",
    "    Ntrain = len(Y) // 2\n",
    "    Xtrain, Ytrain = X[:Ntrain], Y[:Ntrain]\n",
    "    Xtest, Ytest = X[Ntrain:], Y[Ntrain:]\n",
    "    \n",
    "    model = DecisionTree()\n",
    "    # model = DecisionTree(max_depth=7)\n",
    "    t0 = datetime.now()\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    print(\"Training time:\", (datetime.now() - t0))\n",
    "\n",
    "    t0 = datetime.now()\n",
    "    print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "    print(\"Time to compute train accuracy:\", (datetime.now() - t0))\n",
    "\n",
    "    t0 = datetime.now()\n",
    "    print(\"Test accuracy:\", model.score(Xtest, Ytest))\n",
    "    print(\"Time to compute test accuracy:\", (datetime.now() - t0))\n",
    "\n",
    "    # test SKLearn\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    model = DecisionTreeClassifier()\n",
    "    t0 = datetime.now()\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    print(\"SK: Training time:\", (datetime.now() - t0))\n",
    "\n",
    "    t0 = datetime.now()\n",
    "    print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "    print(\"SK: Time to compute train accuracy:\", (datetime.now() - t0))\n",
    "\n",
    "    t0 = datetime.now()\n",
    "    print(\"Test accuracy:\", model.score(Xtest, Ytest))\n",
    "    print(\"SK: Time to compute test accuracy:\", (datetime.now() - t0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n",
      "Training time: 0:00:35.265000\n",
      "Train accuracy: 1.0\n",
      "Time to compute train accuracy: 0:00:00.016000\n",
      "Test accuracy: 0.991833030853\n",
      "Time to compute test accuracy: 0:00:00.047000\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree for continuous-vector input, binary output\n",
    "from __future__ import print_function, division\n",
    "from future.utils import iteritems\n",
    "from builtins import range, input\n",
    "\n",
    "import numpy as np\n",
    "from util import get_data, get_xor, get_donut\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def entropy(y):\n",
    "    # assume y is binary - 0 or 1\n",
    "    N = len(y)\n",
    "    s1 = (y == 1).sum()\n",
    "    if 0 == s1 or N == s1:\n",
    "        return 0\n",
    "    p1 = float(s1) / N\n",
    "    p0 = 1 - p1\n",
    "    return -p0*np.log2(p0) - p1*np.log2(p1)\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, depth=0, max_depth=None):\n",
    "        # print 'depth:', depth\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        if len(Y) == 1 or len(set(Y)) == 1:\n",
    "            # base case, only 1 sample\n",
    "            # another base case\n",
    "            # this node only receives examples from 1 class\n",
    "            # we can't make a split\n",
    "            self.col = None\n",
    "            self.split = None\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "            self.prediction = Y[0]\n",
    "\n",
    "        else:\n",
    "            D = X.shape[1]\n",
    "            cols = range(D)\n",
    "\n",
    "            max_ig = 0\n",
    "            best_col = None\n",
    "            best_split = None\n",
    "            for col in cols:\n",
    "                ig, split = self.find_split(X, Y, col)\n",
    "                # print \"ig:\", ig\n",
    "                if ig > max_ig:\n",
    "                    max_ig = ig\n",
    "                    best_col = col\n",
    "                    best_split = split\n",
    "\n",
    "            if max_ig == 0:\n",
    "                # nothing we can do\n",
    "                # no further splits\n",
    "                self.col = None\n",
    "                self.split = None\n",
    "                self.left = None\n",
    "                self.right = None\n",
    "                self.prediction = np.round(Y.mean())\n",
    "            else:\n",
    "                self.col = best_col\n",
    "                self.split = best_split\n",
    "\n",
    "                if self.depth == self.max_depth:\n",
    "                    self.left = None\n",
    "                    self.right = None\n",
    "                    self.prediction = [\n",
    "                        np.round(Y[X[:,best_col] < self.split].mean()),\n",
    "                        np.round(Y[X[:,best_col] >= self.split].mean()),\n",
    "                    ]\n",
    "                else:\n",
    "                    # print \"best split:\", best_split\n",
    "                    left_idx = (X[:,best_col] < best_split)\n",
    "                    # print \"left_idx.shape:\", left_idx.shape, \"len(X):\", len(X)\n",
    "                    Xleft = X[left_idx]\n",
    "                    Yleft = Y[left_idx]\n",
    "                    self.left = TreeNode(self.depth + 1, self.max_depth)\n",
    "                    self.left.fit(Xleft, Yleft)\n",
    "\n",
    "                    right_idx = (X[:,best_col] >= best_split)\n",
    "                    Xright = X[right_idx]\n",
    "                    Yright = Y[right_idx]\n",
    "                    self.right = TreeNode(self.depth + 1, self.max_depth)\n",
    "                    self.right.fit(Xright, Yright)\n",
    "\n",
    "    def find_split(self, X, Y, col):\n",
    "        # print \"finding split for col:\", col\n",
    "        x_values = X[:, col]\n",
    "        sort_idx = np.argsort(x_values)\n",
    "        x_values = x_values[sort_idx]\n",
    "        y_values = Y[sort_idx]\n",
    "\n",
    "        # Note: optimal split is the midpoint between 2 points\n",
    "        # Note: optimal split is only on the boundaries between 2 classes\n",
    "\n",
    "        # if boundaries[i] is true\n",
    "        # then y_values[i] != y_values[i+1]\n",
    "        # nonzero() gives us indices where arg is true\n",
    "        # but for some reason it returns a tuple of size 1\n",
    "        boundaries = np.nonzero(y_values[:-1] != y_values[1:])[0]\n",
    "        best_split = None\n",
    "        max_ig = 0\n",
    "        for b in boundaries:\n",
    "            split = (x_values[b] + x_values[b+1]) / 2\n",
    "            ig = self.information_gain(x_values, y_values, split)\n",
    "            if ig > max_ig:\n",
    "                max_ig = ig\n",
    "                best_split = split\n",
    "        return max_ig, best_split\n",
    "\n",
    "    def information_gain(self, x, y, split):\n",
    "        # assume classes are 0 and 1\n",
    "        # print \"split:\", split\n",
    "        y0 = y[x < split]\n",
    "        y1 = y[x >= split]\n",
    "        N = len(y)\n",
    "        y0len = len(y0)\n",
    "        if y0len == 0 or y0len == N:\n",
    "            return 0\n",
    "        p0 = float(len(y0)) / N\n",
    "        p1 = 1 - p0 #float(len(y1)) / N\n",
    "        # print \"entropy(y):\", entropy(y)\n",
    "        # print \"p0:\", p0\n",
    "        # print \"entropy(y0):\", entropy(y0)\n",
    "        # print \"p1:\", p1\n",
    "        # print \"entropy(y1):\", entropy(y1)\n",
    "        return entropy(y) - p0*entropy(y0) - p1*entropy(y1)\n",
    "\n",
    "    def predict_one(self, x):\n",
    "        # use \"is not None\" because 0 means False\n",
    "        if self.col is not None and self.split is not None:\n",
    "            feature = x[self.col]\n",
    "            if feature < self.split:\n",
    "                if self.left:\n",
    "                    p = self.left.predict_one(x)\n",
    "                else:\n",
    "                    p = self.prediction[0]\n",
    "            else:\n",
    "                if self.right:\n",
    "                    p = self.right.predict_one(x)\n",
    "                else:\n",
    "                    p = self.prediction[1]\n",
    "        else:\n",
    "            # corresponds to having only 1 prediction\n",
    "            p = self.prediction\n",
    "        return p\n",
    "\n",
    "    def predict(self, X):\n",
    "        N = len(X)\n",
    "        P = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            P[i] = self.predict_one(X[i])\n",
    "        return P\n",
    "\n",
    "\n",
    "# This class is kind of redundant\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.root = TreeNode(max_depth=self.max_depth)\n",
    "        self.root.fit(X, Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.root.predict(X)\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        P = self.predict(X)\n",
    "        return np.mean(P == Y)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X, Y = get_data()\n",
    "\n",
    "    # try donut and xor\n",
    "    # from sklearn.utils import shuffle\n",
    "    # X, Y = get_xor()\n",
    "    # # X, Y = get_donut()\n",
    "    # X, Y = shuffle(X, Y)\n",
    "\n",
    "    # only take 0s and 1s since we're doing binary classification\n",
    "    idx = np.logical_or(Y == 0, Y == 1)\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "\n",
    "    # split the data\n",
    "    Ntrain = len(Y) // 2\n",
    "    Xtrain, Ytrain = X[:Ntrain], Y[:Ntrain]\n",
    "    Xtest, Ytest = X[Ntrain:], Y[Ntrain:]\n",
    "    \n",
    "    model = DecisionTree()\n",
    "    # model = DecisionTree(max_depth=7)\n",
    "    t0 = datetime.now()\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    print(\"Training time:\", (datetime.now() - t0))\n",
    "\n",
    "    t0 = datetime.now()\n",
    "    print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "    print(\"Time to compute train accuracy:\", (datetime.now() - t0))\n",
    "\n",
    "    t0 = datetime.now()\n",
    "    print(\"Test accuracy:\", model.score(Xtest, Ytest))\n",
    "    print(\"Time to compute test accuracy:\", (datetime.now() - t0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
